{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code\n",
    "Welcome to the training code. The first thing you will want to do is to change parameters like training data location, weight storage location, epoch record location, etc. Scroll down to the section titled, \"Training code for 2D spatially-varying deconvolutions\" for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%debug\n",
    "\n",
    "import os, glob\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rc('image', cmap='inferno')\n",
    "\n",
    "import models.model_2d as mod\n",
    "import forward_model_tf as fm\n",
    "import utils as ut\n",
    "\n",
    "# for resizing PSFs as appropriate:\n",
    "import cv2\n",
    "\n",
    "import load_PSFs\n",
    "\n",
    "import sys\n",
    "# sys.path.append(\"../data/denoising_experiments/\")\n",
    "sys.path.append(\"../common/\")\n",
    "import denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training code for 2D spatially-varying deconvolutions\n",
    "Below, I have a whole bunch of settings for some meta-information: where PSFs are stored, where training data is stored, where to store learned weights and epoch metrics etc. The first thing you will see in the block labeled, \"one setting to rule them all,\" is the setting of the `preset` variable. This is NOT NEEDED: if it is unset, or set to something that isn't mentioned in the block labeled, \"preset definitions,\" all these values will be set as per the block labeled, \"Default Settings\". \n",
    "\n",
    "Otherwise, if it is set to something mentioned in \"preset definitions\", the values corresponding to that definition will override only those settings mentioned in the `if` block corresponding to that preset. The rest of the settings will match the default settings.\n",
    "\n",
    "In general, I found the best-performing network to be the one labeled `noisy_5_test`. I encourage you to make a new preset by adding another `elif` statement to the preset definitions and setting the `preset` in the `one setting to rule them all` block to your newly invented preset name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a new preset\n",
    "Comment out the definition of the `preset = noisy_5_test` and add a new definition below that.\n",
    "For example, paste in:\n",
    "```python\n",
    "preset = \"my_noisy_5\"\n",
    "```\n",
    "\n",
    "After this, proceed to Step 2 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one setting to rule them all\n",
    "\n",
    "# preset = 'single_depth_probe'\n",
    "# preset = 'single_depth_probe_noisy'\n",
    "# preset = 'single_depth_probe_noisy_11'\n",
    "# preset = 'multiple_depths_probe'\n",
    "# preset = 'probe_noisy_11_unshifted'\n",
    "# preset = 'probe_noisy_11_unshifted_crazy'\n",
    "# preset = 'probe_noisy_unshifted_equivariant'\n",
    "preset = 'noisy_5_test'\n",
    "# preset = 'new_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Settings\n",
    "\n",
    "# declare all the variables that control how the model is set up and trained.\n",
    "# Point to the training data:\n",
    "# target_dir = '../data/TrainingData/Ground_truth_downsampled/'  # path to objects (ground truth)\n",
    "# input_dir = '../data/TrainingData/Simulated_Miniscope_2D_Training_data/'    # path to simulated measurements (inputs to deconv.)\n",
    "\n",
    "target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "# input_dir = '../data/nV3_simulated/'    # path to simulated measurements (inputs to deconv.)\n",
    "# input_dir = '../data/nV3_mastermat_bare/'    # path to simulated measurements (inputs to deconv.)\n",
    "input_dir = '../data/nV3_mastermat_probe_unshifted/'    # path to simulated measurements (inputs to deconv.)\n",
    "# input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "# input_dirs = ['../data/nV3_mastermat_probe_unshifted/']  \n",
    "# input_dirs = ['../data/nV3_mastermat_probe_unshifted_depth1/',\n",
    "#              '../data/nV3_mastermat_probe_unshifted_depth2/',\n",
    "#              '../data/nV3_mastermat_probe_unshifted_depth3/']\n",
    "\n",
    "# target_dir = '../data/TrainingData/Ground_truth_downsampled/'\n",
    "# input_dir = '../data/TrainingData/Simulated_Miniscope_2D_Training_data/'\n",
    "\n",
    "# PSF load type: could be \"matlab\"\n",
    "# psf_loadtype = \"matlab\"\n",
    "psf_loadtype = \"csv\"\n",
    "\n",
    "# PSF locations, if psf_loadtype==\"matlab\"\n",
    "filter_init_path = '../data/multiWienerPSFStack_40z_aligned.mat' # initialize with 9 PSFs\n",
    "filter_key = 'multiWienerPSFStack_40z'  # key to load in\n",
    "\n",
    "# multiple_psfs = False\n",
    "multiple_psfs = True\n",
    "\n",
    "# PSF directory, if psf_loadtype==\"csv\"\n",
    "# psfs_path = '../data/nV3_PSFs'\n",
    "# psfs_path = \"../data/nV3_PSFs_flat_hd\"\n",
    "psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "psfs_paths = [\"../data/nV3_PSFs_probe_mark_green\"]\n",
    "# psfs_paths = [\"../data/nV3_PSFs_probe_depth1/\", \"../data/nV3_PSFs_probe_depth2/\", \"../data/nV3_PSFs_probe_depth3/\"]\n",
    "# meta_path = '../data/nV3_PSFs_meta/PSF_Shifts.csv'\n",
    "# meta_path = \"../data/nV3_PSFs_flat_meta/metafile_hd.csv\"\n",
    "meta_path = \"../data/nV3_PSFs_meta/metafile_probe_mark.csv\"\n",
    "meta_paths = [\"../data/nV3_PSFs_probe_depths/metafile_probe_depth1.csv\", \\\n",
    "              \"../data/nV3_PSFs_probe_depths/metafile_probe_depth2.csv\",\n",
    "             \"../data/nV3_PSFs_probe_depths/metafile_probe_depth3.csv\"]\n",
    "\n",
    "# Pixel size of the images we're dealing with. This must be the same as the desired PSF size. \n",
    "# Program will adjust size of PSFs by linear interpolation as needed, but will only crop images.\n",
    "# img_dims is (width, height)\n",
    "img_dims = (1280, 800)\n",
    "# img_dims = (648, 486)\n",
    "\n",
    "# choose network type to train\n",
    "model_type='multiwiener' # choices are 'multiwiener', 'wiener', 'unet'\n",
    "\n",
    "# IMPORTANT! CHANGE WHEN NEEDED!\n",
    "# where to store weights and training info\n",
    "# training_location = \"saved_models/multiwiener_nV3_bare/model_weights\"\n",
    "# epochlog_location = \"saved_models/multiwiener_nV3_bare/epoch.log\"\n",
    "# training_location = \"saved_models/multiwiener_nV3_probe/model_weights\"\n",
    "training_location = \"saved_models/multiwiener_nV3_probe_depths/model_weights\"\n",
    "# epochlog_location = \"saved_models/multiwiener_nV3_probe/epoch.log\"\n",
    "epochlog_location = \"saved_models/multiwiener_nV3_probe_depths/epoch.log\"\n",
    "# training_location = \"saved_models/waller/model_weights\"\n",
    "# epochlog_location = \"saved_models/waller/epoch.log\"\n",
    "\n",
    "# legacy_training decides whether to use the old way of training, with GradientTape etc\n",
    "# or the more standard model.fit() approach.\n",
    "# The former was used by the original Waller code, but seems to work better.\n",
    "legacy_training = True\n",
    "smallset = False # if True, will train on a small subset of the dataset to make things a bit faster.\n",
    "backup_location = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the preset used above\n",
    "At the bottom of the \"preset definitions\" block below, paste in something like the following:\n",
    "```python\n",
    "elif preset == 'my_noisy_5':\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/my_psfs/'    # path to simulated measurements (inputs to deconv.)\n",
    "    training_location = \"saved_models/my_noisy_5/model_weights\"\n",
    "    epochlog_location = \"saved_models/my_noisy_5/epoch.log\"\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "    pooling='average'\n",
    "```\n",
    "\n",
    "The line defining `input_dir` sets the path to the simulated images.\n",
    "\n",
    "The line defining `training_location` defines where the model weights will be stored.\n",
    "\n",
    "The line defining `epochlog_location` defines where the log of the present epoch should be stored.\n",
    "\n",
    "`crazy_external_noise_addition` enables the bahaviour used during training of the most successful model, where the background of the ground truth images was boosted by the mean of the added Gaussian noise.\n",
    "\n",
    "`training_noise_sigma` defines the standard deviation of the added Gaussian noise\n",
    "\n",
    "`pooling` defines the type of pooling layer to use. This can be `average`, `max`, `averageblur` or `maxblur`. The last two are implementations of the BlurPool layers introduced by [(Zhang, 2019)](https://arxiv.org/abs/1904.11486).\n",
    "\n",
    "The name, i.e. `my_noisy_5` should match the preset you set in Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preset definitions\n",
    "\n",
    "if preset == 'single_depth_probe':\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/'    # path to simulated measurements (inputs to deconv.)\n",
    "    psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe/epoch.log\"\n",
    "if preset == 'single_depth_probe_noisy':\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_unshifted/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy2/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy2/epoch.log\"\n",
    "    training_noise_sigma=4.2\n",
    "elif preset == 'multiple_depths_probe':\n",
    "    multiple_psfs = True\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dirs = ['../data/nV3_mastermat_probe_unshifted_depth1/',\n",
    "             '../data/nV3_mastermat_probe_unshifted_depth2/',\n",
    "             '../data/nV3_mastermat_probe_unshifted_depth3/']\n",
    "    psfs_paths = [\"../data/nV3_PSFs_probe_depth1/\", \n",
    "                  \"../data/nV3_PSFs_probe_depth2/\", \n",
    "                  \"../data/nV3_PSFs_probe_depth3/\"]\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_depths/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_depths/epoch.log\"\n",
    "elif preset == 'single_depth_probe_noisy_11':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_unshifted/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy3/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy3/epoch.log\"\n",
    "    training_noise_sigma=11/255\n",
    "elif preset == 'probe_noisy_11_unshifted':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy4/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy4/epoch.log\"\n",
    "    training_noise_sigma=11/255\n",
    "elif preset == 'probe_noisy_11_unshifted_crazy':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy5/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy5/epoch.log\"\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "    pooling='average'\n",
    "elif preset == 'probe_noisy_unshifted_equivariant':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_equivariant/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_equivariant/epoch.log\"\n",
    "#     pooling = 'maxblur'\n",
    "    pooling = 'averageblur'\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "elif preset == 'noisy_5_test':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/noisy_5_test/model_weights\"\n",
    "    epochlog_location = \"saved_models/noisy_5_test/epoch.log\"\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "    pooling='average'\n",
    "elif preset == 'new_code':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"../data/nV3_PSFs_probe_mark_green\"\n",
    "#     training_location = \"saved_models/multiwiener_nV3_probe_noisy5_new_way/model_weights\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy5_new_way2/model_weights\"\n",
    "#     epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy5/epoch.log\"\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "    pooling='average'\n",
    "    legacy_training = False\n",
    "    smallset=True\n",
    "    backup_location = \"saved_models/multiwiener_nV3_probe_noisy5_new_way2/backup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run the notebook\n",
    "Now, you should be good to run the entire notebook! Press the \"Restart, and run all\" button at the top of this window.\n",
    "\n",
    "This should take you down to the training block. Above this block is Step 4, which details how to stop training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple_psfs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = [input_dir]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset and dataloader for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 1\n",
    "# batch_size = 2\n",
    "# batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if multiple_psfs:\n",
    "    target_path = (sorted(glob.glob(target_dir + '*')))*len(input_dirs)\n",
    "    input_path_lists = [(sorted(glob.glob(input_dir + '*'))) for input_dir in input_dirs]\n",
    "    input_path = []\n",
    "    for pathset in input_path_lists:\n",
    "        for path in pathset:\n",
    "            input_path.append(path)\n",
    "else:\n",
    "    input_path = sorted(glob.glob(input_dir + '*'))\n",
    "    target_path = sorted(glob.glob(target_dir + '*'))\n",
    "\n",
    "image_count=len(os.listdir(target_dir))\n",
    "print(image_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/nV3_resized/9999.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_path[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16595\n",
      "5531\n",
      "16595\n",
      "5531\n"
     ]
    }
   ],
   "source": [
    "# Create a first dataset of file paths and labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_path, target_path))\n",
    "dataset = dataset.shuffle(image_count, seed=0, reshuffle_each_iteration=False)\n",
    "\n",
    "\n",
    "# Split into train/validation\n",
    "if smallset:\n",
    "    val_size = int(5)\n",
    "    train_ds = dataset.skip(val_size).take(20)\n",
    "else:\n",
    "    val_size = int(image_count * 0.25)\n",
    "    # took a small number of samples for test training to make epochs go faster\n",
    "    train_ds = dataset.skip(val_size)\n",
    "#train_ds = dataset.skip(val_size).take(100)\n",
    "\n",
    "    \n",
    "val_ds = dataset.take(val_size)\n",
    "\n",
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())\n",
    "\n",
    "train_ds = train_ds.map(ut.parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(ut.parse_function, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_ds = ut.configure_for_performance(train_ds,batch_size)\n",
    "val_ds = ut.configure_for_performance(val_ds,batch_size)\n",
    "\n",
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in train_ds:\n",
    "#     print(\"x has shape: \", x.shape)\n",
    "#     print(\"y has shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# plt.imshow(imageio.imread('../data/nV3_mastermat_bare/1079.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.get_single_element?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualzie data to make sure all is good\n",
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "# input_batch, target_batch = next(iter(val_ds))\n",
    "# f, ax = plt.subplots(1, 2, figsize=(15,15))\n",
    "\n",
    "# ax[0].imshow(input_batch[0,:,:,0] + np.random.normal(scale=training_noise_sigma, size=input_batch[0,:,:,0].shape), vmax = 1)\n",
    "# ax[0].set_title('Input Data')\n",
    "\n",
    "# ax[1].imshow(target_batch[0,:,:,0], vmax = 1)\n",
    "# ax[1].set_title('Target Data')\n",
    "\n",
    "# print(input_batch[0,:,:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(input_batch[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in input_path:\n",
    "#     try:\n",
    "#         print(path)\n",
    "#         imageio.imread(path)\n",
    "#     except:\n",
    "#         print(\"BROKEN: \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in Psfs and initialize network to train\n",
    "\n",
    "Here we initialize with 9 PSFs taken from different parts in the field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1280, 21)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "import csv_psfs\n",
    "# from IPython.core.debugger import set_trace\n",
    "\n",
    "# load the PSFs\n",
    "if psf_loadtype == \"matlab\":\n",
    "    registered_psfs_path = filter_init_path\n",
    "    psfs = scipy.io.loadmat(registered_psfs_path)\n",
    "    psfs=psfs[filter_key]\n",
    "elif psf_loadtype == \"csv\":\n",
    "#     # expect a directory with a bunch of PSFs therein as separate csvs;\n",
    "#     # list out all csv file names in the directory\n",
    "#     psf_paths = glob.glob(psfs_path.removesuffix('/') + '/*')\n",
    "#     # iterate through that list,\n",
    "#     # open and append each to the psfs array,\n",
    "#     psfs = [[]]\n",
    "#     for path in psf_paths:\n",
    "#         #psfs[0].append(np.loadtxt(path, delimiter=',', encoding='utf-8-sig'))\n",
    "#         psfs[0].append(np.loadtxt(path, delimiter=','))\n",
    "#     # convert the psfs array to an np.ndarray\n",
    "#     psfs = np.transpose(np.asarray(psfs), (2,3,1,0))\n",
    "#     set_trace()\n",
    "##     psfs = load_PSFs.load_PSFs_csv(psfs_path, meta_path, img_dims)[:,:,:,0]\n",
    "#     if not multiple_psfs: \n",
    "#         psfs = csv_psfs.pad_as_center(csv_psfs.load_from_dir(psfs_path), img_dims[1], img_dims[0])\n",
    "\n",
    "# handle multiple sets of PSFs:\n",
    "    # FIXME: magic number 63 is 3*the number of PSFs per metafile\n",
    "    if multiple_psfs:\n",
    "        psfs = np.empty((img_dims[1], img_dims[0], 21*3))\n",
    "        for i in range(len(psfs_paths)):\n",
    "            psfs[:,:,i:i+21] = csv_psfs.pad_as_center(csv_psfs.load_from_dir(psfs_paths[i]), img_dims[1], img_dims[0])\n",
    "    else:\n",
    "        psfs = csv_psfs.pad_as_center(csv_psfs.load_from_dir(psfs_path), img_dims[1], img_dims[0])\n",
    "else:\n",
    "    raise ValueError(\"Not sure how to load PSFs\")\n",
    "psfs.shape\n",
    "\n",
    "# for testing, cut the psf and look at padding behaviour\n",
    "#psfs = psfs[162:324, 216:432, :, :]\n",
    "#psfs.shape\n",
    "# Test result: it works!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1280, 21)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the PSFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa49201e6d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 10\n",
    "plt.imshow(psfs[368:432,608:672,ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it seems that the PSFs indeed start out centered. This means that something happens during training to cause them to shift around. I wonder if it's possible that the model I've been interrogating was trained on distorted data (that would explain this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(psfs_paths) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"string\") == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1280, 21)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1280, 21)\n",
      "(800, 1280, 21)\n"
     ]
    }
   ],
   "source": [
    "# set_trace()\n",
    "\n",
    "if model_type=='unet':\n",
    "    model =mod.UNet(486, 648, \n",
    "                             encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                             center_cs=1024,\n",
    "                             decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                             skip_connections=[True, True, True, True, True, False])\n",
    "elif model_type=='wiener':\n",
    "\n",
    "    registered_psfs_path = filter_init_path\n",
    "    psfs = scipy.io.loadmat(registered_psfs_path)\n",
    "    psfs=psfs[filter_key]\n",
    "    psfs=psfs[:,:,0,0]\n",
    "    psfs=psfs/np.max(psfs)\n",
    "    \n",
    "    Ks=1\n",
    "\n",
    "    model = mod.UNet_wiener(486, 648, psfs, Ks, \n",
    "                             encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                             center_cs=1024,\n",
    "                             decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                             skip_connections=[True, True, True, True, True, False])\n",
    "    \n",
    "    print(psfs.shape, 1)\n",
    "    \n",
    "elif model_type=='multiwiener':\n",
    "    # assume psfs is already 3-dimensional if our PSFs are used\n",
    "    # if matlab-style is used, it's typically an academic who likes 4D\n",
    "    if psf_loadtype == \"matlab\":\n",
    "        psfs=psfs[:,:,:,0]\n",
    "    print(psfs.shape)\n",
    "    #psfs = cv2.resize(psfs, img_dims)\n",
    "    # rather than resizing, zero-pad to appropriate size\n",
    "    # this means that original PSF can be any size, but Image Delta must be set correctly\n",
    "    \n",
    "    print(psfs.shape)\n",
    "    psfs=psfs/np.max(psfs)\n",
    "    if multiple_psfs:\n",
    "        psfs_keep = psfs[:,:,list(range(0,11))+list(range(21,32))+list(range(43,54))]*1\n",
    "#         psfs_keep = psfs*1\n",
    "    #     psfs_keep = psfs[:,:,list(range(0,11))+list(range(21,32))]*1\n",
    "    #     psfs_keep = psfs[:,:,0:21]*1\n",
    "        print(psfs_keep.shape)\n",
    "\n",
    "    #     Ks =np.ones((1,1,psfs.shape[2]))\n",
    "        Ks_keep = np.ones((1,1,psfs_keep.shape[2]))\n",
    "        print(Ks_keep.shape)\n",
    "\n",
    "        model =mod.UNet_multiwiener_resize(img_dims[1], img_dims[0], psfs_keep, Ks_keep, \n",
    "                             encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                             center_cs=1024,\n",
    "                             decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                             skip_connections=[True, True, True, True, True, False], psfs_trainable=True)\n",
    "#     model =mod.UNet_multiwiener_resize(img_dims[1], img_dims[0], psfs, Ks, \n",
    "#                          encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "#                          center_cs=1024,\n",
    "#                          decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "#                          skip_connections=[True, True, True, True, True, False])\n",
    "\n",
    "# made PSFs untrainable\n",
    "    else:\n",
    "        Ks =np.ones((1,1,psfs.shape[2]))\n",
    "        model =mod.UNet_multiwiener_resize(img_dims[1], img_dims[0], psfs, Ks, \n",
    "                             encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                             center_cs=1024,\n",
    "                             decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                             skip_connections=[True, True, True, True, True, False], psfs_trainable=True,\n",
    "                                training_noise=True,\n",
    "                                training_noise_sigma=training_noise_sigma,\n",
    "                                pooling=pooling)\n",
    "#     model =mod.UNet_multiwiener_resize(img_dims[1], img_dims[0], psfs_keep, Ks_keep, \n",
    "#                          encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "#                          center_cs=1024,\n",
    "#                          decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "#                          skip_connections=[True, True, True, True, True, False], psfs_trainable=True)\n",
    "    \n",
    "#     print('initialized filter shape:', psfs.shape, 'initialized K shape:', Ks.shape)\n",
    "# print('initialized filter shape:', psfs_keep.shape, 'initialized K shape:', Ks_keep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1280, 21)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 800, 1280,   0           []                               \n",
      "                                1)]                                                               \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNoise)  (None, 800, 1280, 1  0          ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " multi_wiener_deconvolution (Mu  (None, 800, 1280, 2  21504021   ['gaussian_noise[0][0]']         \n",
      " ltiWienerDeconvolution)        1)                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 800, 1280, 2  4536        ['multi_wiener_deconvolution[0][0\n",
      "                                4)                               ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 800, 1280, 2  96         ['conv2d[0][0]']                 \n",
      " alization)                     4)                                                                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 800, 1280, 2  0           ['batch_normalization[0][0]']    \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 800, 1280, 2  5184        ['activation[0][0]']             \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 800, 1280, 2  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 800, 1280, 2  0           ['batch_normalization_1[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 400, 640, 24  0          ['activation_1[0][0]']           \n",
      " ing2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 400, 640, 64  13824       ['average_pooling2d[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 400, 640, 64  256        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 400, 640, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 400, 640, 64  36864       ['activation_2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 400, 640, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 400, 640, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 200, 320, 64  0          ['activation_3[0][0]']           \n",
      " oling2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 200, 320, 12  73728       ['average_pooling2d_1[0][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 200, 320, 12  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 200, 320, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 200, 320, 12  147456      ['activation_4[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 200, 320, 12  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 200, 320, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 100, 160, 12  0          ['activation_5[0][0]']           \n",
      " oling2D)                       8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 100, 160, 25  294912      ['average_pooling2d_2[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 100, 160, 25  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 100, 160, 25  0           ['batch_normalization_6[0][0]']  \n",
      "                                6)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 100, 160, 25  589824      ['activation_6[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 100, 160, 25  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 100, 160, 25  0           ['batch_normalization_7[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 50, 80, 256)  0          ['activation_7[0][0]']           \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 50, 80, 512)  1179648     ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 50, 80, 512)  2048       ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 50, 80, 512)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 50, 80, 512)  2359296     ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 50, 80, 512)  2048       ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 50, 80, 512)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 25, 40, 512)  0          ['activation_9[0][0]']           \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 40, 1024  4718592     ['average_pooling2d_4[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 25, 40, 1024  4096       ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 25, 40, 1024  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 40, 1024  9437184     ['activation_10[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 25, 40, 1024  4096       ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 25, 40, 1024  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 12, 20, 1024  0          ['activation_11[0][0]']          \n",
      " oling2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 12, 20, 1024  9437184     ['average_pooling2d_5[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 12, 20, 1024  4096       ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 12, 20, 1024  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.image.resize (TFOpLambda)   (None, 25, 40, 1024  0           ['activation_12[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 25, 40, 2048  0           ['tf.image.resize[0][0]',        \n",
      "                                )                                 'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 25, 40, 512)  9437184     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 25, 40, 512)  2048       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 25, 40, 512)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 25, 40, 512)  2359296     ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 25, 40, 512)  2048       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 25, 40, 512)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 25, 40, 512)  2359296     ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 25, 40, 512)  2048       ['conv2d_15[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 25, 40, 512)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " tf.image.resize_1 (TFOpLambda)  (None, 50, 80, 512)  0          ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 50, 80, 1024  0           ['tf.image.resize_1[0][0]',      \n",
      "                                )                                 'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 50, 80, 256)  2359296     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 50, 80, 256)  1024       ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 50, 80, 256)  0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 50, 80, 256)  589824      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 50, 80, 256)  1024       ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 50, 80, 256)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 50, 80, 256)  589824      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 50, 80, 256)  1024       ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 50, 80, 256)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " tf.image.resize_2 (TFOpLambda)  (None, 100, 160, 25  0          ['activation_18[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 100, 160, 51  0           ['tf.image.resize_2[0][0]',      \n",
      "                                2)                                'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 100, 160, 12  589824      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 100, 160, 12  512        ['conv2d_19[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 100, 160, 12  0           ['batch_normalization_19[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 100, 160, 12  147456      ['activation_19[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 100, 160, 12  512        ['conv2d_20[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 100, 160, 12  0           ['batch_normalization_20[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 100, 160, 12  147456      ['activation_20[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 100, 160, 12  512        ['conv2d_21[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 100, 160, 12  0           ['batch_normalization_21[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " tf.image.resize_3 (TFOpLambda)  (None, 200, 320, 12  0          ['activation_21[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 200, 320, 25  0           ['tf.image.resize_3[0][0]',      \n",
      "                                6)                                'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 200, 320, 64  147456      ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 200, 320, 64  256        ['conv2d_22[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 200, 320, 64  0           ['batch_normalization_22[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 200, 320, 64  36864       ['activation_22[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 200, 320, 64  256        ['conv2d_23[0][0]']              \n",
      " ormalization)                  )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 200, 320, 64  0           ['batch_normalization_23[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 200, 320, 64  36864       ['activation_23[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 200, 320, 64  256        ['conv2d_24[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 200, 320, 64  0           ['batch_normalization_24[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.image.resize_4 (TFOpLambda)  (None, 400, 640, 64  0          ['activation_24[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 400, 640, 12  0           ['tf.image.resize_4[0][0]',      \n",
      "                                8)                                'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 400, 640, 24  27648       ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 400, 640, 24  96         ['conv2d_25[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 400, 640, 24  0           ['batch_normalization_25[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 400, 640, 24  5184        ['activation_25[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 400, 640, 24  96         ['conv2d_26[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 400, 640, 24  0           ['batch_normalization_26[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 400, 640, 24  5184        ['activation_26[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 400, 640, 24  96         ['conv2d_27[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 400, 640, 24  0           ['batch_normalization_27[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 800, 1280, 2  0           ['activation_27[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 800, 1280, 2  5184        ['up_sampling2d[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 800, 1280, 2  96         ['conv2d_28[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 800, 1280, 2  0           ['batch_normalization_28[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 800, 1280, 2  5184        ['activation_28[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 800, 1280, 2  96         ['conv2d_29[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 800, 1280, 2  0           ['batch_normalization_29[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 800, 1280, 2  5184        ['activation_29[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 800, 1280, 2  96         ['conv2d_30[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 800, 1280, 2  0           ['batch_normalization_30[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 800, 1280, 1  25          ['activation_30[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 800, 1280)   0           ['conv2d_31[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 68,688,742\n",
      "Trainable params: 68,672,614\n",
      "Non-trainable params: 16,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if legacy_training:\n",
    "    model.build((None, img_dims[1], img_dims[0], 1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.any(np.isnan(psfs_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_reshaped = tf.convert_to_tensor(np.load(\"../data/fov_indicator.npy\").reshape((1,800,1280,1)), dtype=tf.float32)\n",
    "# indicator_reshaped = tf.convert_to_tensor(np.load(\"../data/fov_indicator.npy\"), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.unbatch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Monitor, stop training\n",
    "If you followed Step 3 correctly, the block below should already be running. It may take a few seconds to a minute to get itself together, and then it will print out the current training status below.\n",
    "\n",
    "That current training status will tell you the current epoch as well as the current \"step\"--the latter is which image or batch you are currently on.\n",
    "\n",
    "When you decide that you want to stop training, you can press the button with the square on it at the top of this window (the \"interrupt kernel\" button). Keep in mind that this will only save the last completed epoch, and any training done on the present epoch will be lost.\n",
    "\n",
    "After doing this, you can proceed to the cells below, or else move onto another notebook, e.g. `Minimal Deconvolution.ipynb`. The latter is the preferred method, since that notebook is made much more user-friendly than everything else I've done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_1830248/4051516729.py\u001b[0m(4)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      2 \u001b[0;31m\u001b[0;31m# Prepare EpochLogger and load weights, if necessary, into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'debug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 4 \u001b[0;31m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mepochlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochlog\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done all the crap\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "# ADDED BY DANIEL:\n",
    "# Prepare EpochLogger and load weights, if necessary, into the model\n",
    "# %debug\n",
    "# set_trace()\n",
    "import epochlog.epochlog as el\n",
    "print(\"done all the crap\")\n",
    "\n",
    "## Training with TF.Dataset\n",
    "initial_learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False) #1e-3 diverges\n",
    "\n",
    "# what's the expected input shape for the model?\n",
    "exp_shape = model.get_config()[\"layers\"][0][\"config\"][\"batch_input_shape\"]\n",
    "print(exp_shape)\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "validtate_loss_results=[]\n",
    "num_epochs = 100\n",
    "loss_func=ut.SSIMLoss_l1_indicator\n",
    "learning_rate_counter=0\n",
    "#for epoch in range(num_epochs):\n",
    "if legacy_training:\n",
    "    epochlogger = el.EpochLogger(model, epochlog_location, training_location)\n",
    "    epochlogger.load_weights()\n",
    "    starting_epoch = epochlogger.epochs_done()\n",
    "    print(\"Starting on epoch number: \" + str(starting_epoch))\n",
    "    for epoch in range(starting_epoch, num_epochs):\n",
    "        validation_loss_avg=tf.keras.metrics.Mean()\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        epoch_accuracy = tf.keras.metrics.MeanSquaredError()\n",
    "\n",
    "        # Training loop\n",
    "        iter_num=0\n",
    "        for x, y in train_ds:\n",
    "            # Optimize the model\n",
    "            #print(\"x shape: \" + str(x.shape))\n",
    "            #print(\"y shape: \" + str(y.shape))\n",
    "            # NOTICE: x.shape = y.shape = (2, 486, 648, 1)\n",
    "            # TODO: resize x and y based on expected dimensions for the model\n",
    "            # Crop to the top left corner of the image to make it fit our size if it is too large\n",
    "            if x.shape[1] > exp_shape[1]:\n",
    "                x = x[:,:exp_shape[1],:,:]\n",
    "            if x.shape[2] > exp_shape[2]:\n",
    "                x = x[:,:,:exp_shape[2],:]\n",
    "            if y.shape[1] > exp_shape[1]:\n",
    "                y = y[:,:exp_shape[1],:,:]\n",
    "            if y.shape[2] > exp_shape[2]:\n",
    "                y = y[:,:,:exp_shape[2],:]\n",
    "    #         loss_value, grads = ut.grad(model,loss_func, x, y)\n",
    "    #         loss_value, grads = ut.grad_universal(model,loss_func, x, y)\n",
    "            if crazy_external_noise_addition:\n",
    "                xy_shifted_arr = denoising.rescale_to_one(\n",
    "                    np.asarray([x + np.random.normal(scale=training_noise_sigma, size=x.shape),y]))\n",
    "                loss_value, grads = ut.grad_universal(model,loss_func, xy_shifted_arr[0], xy_shifted_arr[1].astype(np.float32), \n",
    "                                                      indicator_reshaped, training=False)\n",
    "            else:\n",
    "                loss_value, grads = ut.grad_universal(model,loss_func, x, y, indicator_reshaped)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            # Track progress\n",
    "            epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "\n",
    "            epoch_accuracy.update_state(y, model(x)) \n",
    "            # Print every 1\n",
    "            if iter_num % 1 == 0:\n",
    "                print(\"Epoch {:03d}: Step: {:03d}, Loss: {:.3f}, MSE: {:.3}\".format(epoch, iter_num,epoch_loss_avg.result(),\n",
    "                                                                            epoch_accuracy.result()),end='\\r')\n",
    "            iter_num=iter_num+1\n",
    "\n",
    "\n",
    "\n",
    "      # End epoch\n",
    "        #print(\"Ending Epoch\")\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "\n",
    "        # skip validation, since SSIM function is broken\n",
    "        for x_val, y_val in val_ds:\n",
    "            val_loss_value= loss_func(model, x_val, y_val, indicator_reshaped)\n",
    "            validation_loss_avg.update_state(val_loss_value)\n",
    "\n",
    "\n",
    "        validtate_loss_results.append(validation_loss_avg.result())    \n",
    "        #if epoch % 1 == 0:\n",
    "            #print(\"Epoch {:03d}: MSE: {:.3}, Training Loss: {:.3f}, Validation Loss: {:.3f}\".format(epoch,\n",
    "            #                                                            epoch_accuracy.result(), epoch_loss_avg.result(), \n",
    "            #                                                                                        validation_loss_avg.result()))\n",
    "        epochlogger.done_epoch()\n",
    "else:\n",
    "#     loss_func=ut.SSIMLoss_l1_indicator_generator(indicator_reshaped, training=False)\n",
    "#     loss_func=ut.SSIMLoss_l1_generator(training=False)\n",
    "    loss_func = ut.SSIMLoss_l1_indicator_Class(indicator_reshaped)\n",
    "#     loss_func=ut.Loss_l1_indicator_generator(indicator_reshaped, training=False)\n",
    "    # load the dataset here? Necessary to have separate x and y datasets because that's how fit() takes it\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=training_location,\n",
    "    save_weights_only=True,\n",
    "    verbose=1)\n",
    "    \n",
    "    if backup_location is None:\n",
    "        backup_restore_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=training_location)\n",
    "    else:\n",
    "        backup_restore_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=backup_location)\n",
    "#     model_checkpoint_callback\n",
    "    \n",
    "    model.compile(optimizer, loss=loss_func)\n",
    "#     print(model_checkpoint_callback.best)\n",
    "\n",
    "#     model.load_weights(training_location)\n",
    "    # weirdly, model keeps restarting its training from the first epoch\n",
    "    # made the modification below based on user30012's answer at\n",
    "    # https://stackoverflow.com/questions/45393429/keras-how-to-save-model-and-continue-training\n",
    "#     score = model.evaluate(val_ds)\n",
    "#     model_checkpoint_callback.best = score\n",
    "    \n",
    "#     epochlogger = el.BaseEpochLogger(model, epochlog_location, training_location)\n",
    "#     epochlogger.load_weights()\n",
    "    \n",
    "#     print(model_checkpoint_callback.best)\n",
    "    model.fit(train_ds, epochs=num_epochs, callbacks=[model_checkpoint_callback, backup_restore_callback], \n",
    "             validation_data=val_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if legacy_training:\n",
    "    import epochlog.epochlog as el\n",
    "    epochlogger = el.EpochLogger(model, epochlog_location, training_location)\n",
    "    epochlogger.load_weights()\n",
    "else:\n",
    "    model.load_weights(training_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('./saved_models/multiwiener')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "plt.imshow(imageio.imread(\"../data/noisy_real_images/10.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, target_batch = next(iter(val_ds))\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on validation data\n",
    "input_batch, target_batch = next(iter(val_ds))\n",
    "imnum=0\n",
    "\n",
    "# noisy_input = input_batch + np.random.normal(scale=training_noise_sigma, size=input_batch.shape)\n",
    "noisy_input = input_batch\n",
    "f, ax = plt.subplots(3, 1, figsize=(15,15))\n",
    "# ax[0].imshow((target_batch[imnum,:,:,0]))\n",
    "ax[0].imshow((target_batch[imnum,:,:]))\n",
    "ax[0].set_title('Target Data')\n",
    "\n",
    "# test=model(input_batch[imnum,:,:,0].numpy().reshape((1,486, 648,1)))\n",
    "test=model(noisy_input[imnum,:,:].numpy().reshape((1,img_dims[1], img_dims[0],1)))\n",
    "ax[2].set_title('recon')\n",
    "ax[2].imshow(test[0,:,:1200])\n",
    "\n",
    "ax[1].imshow((noisy_input[imnum,:,:]))\n",
    "ax[1].set_title('Input Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isnan(test[0,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_reconstruct_index = 9\n",
    "# folderpath = \"../data/real_images/\"\n",
    "# to_reconstruct = imageio.imread(folderpath+\"image_\"+str(to_reconstruct_index)+\".png\")\n",
    "# img_path_to_do = \"../data/denoised_real_images/30.png\"\n",
    "img_path_to_do = \"../data/noisy_real_images/40.png\"\n",
    "to_reconstruct = cv2.resize(imageio.imread(img_path_to_do), (1280, 800))\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(15,15))\n",
    "axs[0].imshow(to_reconstruct)\n",
    "axs[1].imshow(model(to_reconstruct.reshape((1,800,1280,1)))[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,128))\n",
    "plt.imshow(model(to_reconstruct.reshape((1,800,1280,1)))[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imageio.imread(\"../data/real_images_unpadded/isxd_9.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training is working, save your model using: \n",
    "\n",
    "    model.save_weights('./saved_models/model_name')\n",
    "\n",
    "You can save after training is complete, or periodically throughout epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first PSF as an example of what we're looking for\n",
    "plt.imshow(psfs[:,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%debug\n",
    "\n",
    "import os, glob\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rc('image', cmap='inferno')\n",
    "\n",
    "import models.model_2d as mod\n",
    "import forward_model_tf as fm\n",
    "import utils as ut\n",
    "\n",
    "# for resizing PSFs as appropriate:\n",
    "import cv2\n",
    "\n",
    "import load_PSFs\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/dshteinbok/denoising_experiments/\")\n",
    "import denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/dshteinbok/miniconda3/envs/tf/lib/python3.9/site-packages/cv2/../../../../lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "/bin/bash: gpustat: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training code for 2D spatially-varying deconvolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one setting to rule them all\n",
    "# preset = 'single_depth_probe'\n",
    "# preset = 'single_depth_probe_noisy'\n",
    "# preset = 'single_depth_probe_noisy_11'\n",
    "# preset = 'multiple_depths_probe'\n",
    "# preset = 'probe_noisy_11_unshifted'\n",
    "# preset = 'probe_noisy_11_unshifted_crazy'\n",
    "# preset = 'probe_noisy_unshifted_equivariant'\n",
    "# preset = 'noisy_5_test'\n",
    "preset = 'new_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare all the variables that control how the model is set up and trained.\n",
    "# Point to the training data:\n",
    "# target_dir = '/home/dshteinbok/TrainingData/Ground_truth_downsampled/'  # path to objects (ground truth)\n",
    "# input_dir = '/home/dshteinbok/TrainingData/Simulated_Miniscope_2D_Training_data/'    # path to simulated measurements (inputs to deconv.)\n",
    "\n",
    "target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "# input_dir = '../data/nV3_simulated/'    # path to simulated measurements (inputs to deconv.)\n",
    "# input_dir = '../data/nV3_mastermat_bare/'    # path to simulated measurements (inputs to deconv.)\n",
    "input_dir = '../data/nV3_mastermat_probe_unshifted/'    # path to simulated measurements (inputs to deconv.)\n",
    "# input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "# input_dirs = ['../data/nV3_mastermat_probe_unshifted/']  \n",
    "# input_dirs = ['../data/nV3_mastermat_probe_unshifted_depth1/',\n",
    "#              '../data/nV3_mastermat_probe_unshifted_depth2/',\n",
    "#              '../data/nV3_mastermat_probe_unshifted_depth3/']\n",
    "\n",
    "# target_dir = '/home/dshteinbok/TrainingData/Ground_truth_downsampled/'\n",
    "# input_dir = '/home/dshteinbok/TrainingData/Simulated_Miniscope_2D_Training_data/'\n",
    "\n",
    "# PSF load type: could be \"matlab\"\n",
    "# psf_loadtype = \"matlab\"\n",
    "psf_loadtype = \"csv\"\n",
    "\n",
    "# PSF locations, if psf_loadtype==\"matlab\"\n",
    "filter_init_path = '../data/multiWienerPSFStack_40z_aligned.mat' # initialize with 9 PSFs\n",
    "filter_key = 'multiWienerPSFStack_40z'  # key to load in\n",
    "\n",
    "# multiple_psfs = False\n",
    "multiple_psfs = True\n",
    "\n",
    "# PSF directory, if psf_loadtype==\"csv\"\n",
    "# psfs_path = '/home/dshteinbok/nV3_PSFs'\n",
    "# psfs_path = \"/home/dshteinbok/nV3_PSFs_flat_hd\"\n",
    "psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "psfs_paths = [\"/home/dshteinbok/nV3_PSFs_probe_mark_green\"]\n",
    "# psfs_paths = [\"/home/dshteinbok/nV3_PSFs_probe_depth1/\", \"/home/dshteinbok/nV3_PSFs_probe_depth2/\", \"/home/dshteinbok/nV3_PSFs_probe_depth3/\"]\n",
    "# meta_path = '/home/dshteinbok/nV3_PSFs_meta/PSF_Shifts.csv'\n",
    "# meta_path = \"/home/dshteinbok/nV3_PSFs_flat_meta/metafile_hd.csv\"\n",
    "meta_path = \"/home/dshteinbok/nV3_PSFs_meta/metafile_probe_mark.csv\"\n",
    "meta_paths = [\"/home/dshteinbok/nV3_PSFs_probe_depths/metafile_probe_depth1.csv\", \\\n",
    "              \"/home/dshteinbok/nV3_PSFs_probe_depths/metafile_probe_depth2.csv\",\n",
    "             \"/home/dshteinbok/nV3_PSFs_probe_depths/metafile_probe_depth3.csv\"]\n",
    "\n",
    "# Pixel size of the images we're dealing with. This must be the same as the desired PSF size. \n",
    "# Program will adjust size of PSFs by linear interpolation as needed, but will only crop images.\n",
    "# img_dims is (width, height)\n",
    "img_dims = (1280, 800)\n",
    "# img_dims = (648, 486)\n",
    "\n",
    "# choose network type to train\n",
    "model_type='multiwiener' # choices are 'multiwiener', 'wiener', 'unet'\n",
    "\n",
    "# IMPORTANT! CHANGE WHEN NEEDED!\n",
    "# where to store weights and training info\n",
    "# training_location = \"saved_models/multiwiener_nV3_bare/model_weights\"\n",
    "# epochlog_location = \"saved_models/multiwiener_nV3_bare/epoch.log\"\n",
    "# training_location = \"saved_models/multiwiener_nV3_probe/model_weights\"\n",
    "training_location = \"saved_models/multiwiener_nV3_probe_depths/model_weights\"\n",
    "# epochlog_location = \"saved_models/multiwiener_nV3_probe/epoch.log\"\n",
    "epochlog_location = \"saved_models/multiwiener_nV3_probe_depths/epoch.log\"\n",
    "# training_location = \"saved_models/waller/model_weights\"\n",
    "# epochlog_location = \"saved_models/waller/epoch.log\"\n",
    "\n",
    "# legacy_training decides whether to use the old way of training, with GradientTape etc\n",
    "# or the more standard model.fit() approach.\n",
    "# The former was used by the original Waller code.\n",
    "legacy_training = True\n",
    "smallset = False\n",
    "backup_location = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if preset == 'single_depth_probe':\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/'    # path to simulated measurements (inputs to deconv.)\n",
    "    psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe/epoch.log\"\n",
    "if preset == 'single_depth_probe_noisy':\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_unshifted/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy2/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy2/epoch.log\"\n",
    "    training_noise_sigma=4.2\n",
    "elif preset == 'multiple_depths_probe':\n",
    "    multiple_psfs = True\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dirs = ['../data/nV3_mastermat_probe_unshifted_depth1/',\n",
    "             '../data/nV3_mastermat_probe_unshifted_depth2/',\n",
    "             '../data/nV3_mastermat_probe_unshifted_depth3/']\n",
    "    psfs_paths = [\"/home/dshteinbok/nV3_PSFs_probe_depth1/\", \n",
    "                  \"/home/dshteinbok/nV3_PSFs_probe_depth2/\", \n",
    "                  \"/home/dshteinbok/nV3_PSFs_probe_depth3/\"]\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_depths/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_depths/epoch.log\"\n",
    "elif preset == 'single_depth_probe_noisy_11':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_unshifted/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy3/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy3/epoch.log\"\n",
    "    training_noise_sigma=11/255\n",
    "elif preset == 'probe_noisy_11_unshifted':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy4/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy4/epoch.log\"\n",
    "    training_noise_sigma=11/255\n",
    "elif preset == 'probe_noisy_11_unshifted_crazy':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy5/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy5/epoch.log\"\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "    pooling='average'\n",
    "elif preset == 'probe_noisy_unshifted_equivariant':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_equivariant/model_weights\"\n",
    "    epochlog_location = \"saved_models/multiwiener_nV3_probe_equivariant/epoch.log\"\n",
    "#     pooling = 'maxblur'\n",
    "    pooling = 'averageblur'\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "elif preset == 'noisy_5_test':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "    training_location = \"saved_models/noisy_5_test/model_weights\"\n",
    "    epochlog_location = \"saved_models/noisy_5_test/epoch.log\"\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "    pooling='average'\n",
    "elif preset == 'new_code':\n",
    "    # noisy with a standard deviation of 11, as observed\n",
    "    multiple_psfs = False\n",
    "    target_dir = '../data/nV3_resized/'  # path to objects (ground truth)\n",
    "    input_dir = '../data/nV3_mastermat_probe_undistorted_corrected/'    # path to simulated measurements (inputs to deconv.)\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted_noisy/'\n",
    "#     input_dir = '../data/nV3_mastermat_probe_unshifted/' # temporary, since we are adding noise on training\n",
    "    psfs_path = \"/home/dshteinbok/nV3_PSFs_probe_mark_green\"\n",
    "#     training_location = \"saved_models/multiwiener_nV3_probe_noisy5_new_way/model_weights\"\n",
    "    training_location = \"saved_models/multiwiener_nV3_probe_noisy5_new_way2/model_weights\"\n",
    "#     epochlog_location = \"saved_models/multiwiener_nV3_probe_noisy5/epoch.log\"\n",
    "    crazy_external_noise_addition = True\n",
    "    training_noise_sigma=11/255\n",
    "    pooling='average'\n",
    "    legacy_training = False\n",
    "    smallset=True\n",
    "    backup_location = \"saved_models/multiwiener_nV3_probe_noisy5_new_way2/backup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple_psfs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dirs = [input_dir]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset and dataloader for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# batch_size = 1\n",
    "# batch_size = 2\n",
    "batch_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if multiple_psfs:\n",
    "    target_path = (sorted(glob.glob(target_dir + '*')))*len(input_dirs)\n",
    "    input_path_lists = [(sorted(glob.glob(input_dir + '*'))) for input_dir in input_dirs]\n",
    "    input_path = []\n",
    "    for pathset in input_path_lists:\n",
    "        for path in pathset:\n",
    "            input_path.append(path)\n",
    "else:\n",
    "    input_path = sorted(glob.glob(input_dir + '*'))\n",
    "    target_path = sorted(glob.glob(target_dir + '*'))\n",
    "\n",
    "image_count=len(os.listdir(target_dir))\n",
    "print(image_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/nV3_resized/9999.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_path[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "5\n",
      "7\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Create a first dataset of file paths and labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_path, target_path))\n",
    "dataset = dataset.shuffle(image_count, seed=0, reshuffle_each_iteration=False)\n",
    "\n",
    "\n",
    "# Split into train/validation\n",
    "if smallset:\n",
    "    val_size = int(5)\n",
    "    train_ds = dataset.skip(val_size).take(20)\n",
    "else:\n",
    "    val_size = int(image_count * 0.25)\n",
    "    # took a small number of samples for test training to make epochs go faster\n",
    "    train_ds = dataset.skip(val_size)\n",
    "#train_ds = dataset.skip(val_size).take(100)\n",
    "\n",
    "    \n",
    "val_ds = dataset.take(val_size)\n",
    "\n",
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())\n",
    "\n",
    "train_ds = train_ds.map(ut.parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.map(ut.parse_function, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_ds = ut.configure_for_performance(train_ds,batch_size)\n",
    "val_ds = ut.configure_for_performance(val_ds,batch_size)\n",
    "\n",
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(val_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, y in train_ds:\n",
    "#     print(\"x has shape: \", x.shape)\n",
    "#     print(\"y has shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# plt.imshow(imageio.imread('../data/nV3_mastermat_bare/1079.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.get_single_element?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualzie data to make sure all is good\n",
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "# input_batch, target_batch = next(iter(val_ds))\n",
    "# f, ax = plt.subplots(1, 2, figsize=(15,15))\n",
    "\n",
    "# ax[0].imshow(input_batch[0,:,:,0] + np.random.normal(scale=training_noise_sigma, size=input_batch[0,:,:,0].shape), vmax = 1)\n",
    "# ax[0].set_title('Input Data')\n",
    "\n",
    "# ax[1].imshow(target_batch[0,:,:,0], vmax = 1)\n",
    "# ax[1].set_title('Target Data')\n",
    "\n",
    "# print(input_batch[0,:,:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(input_batch[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for path in input_path:\n",
    "#     try:\n",
    "#         print(path)\n",
    "#         imageio.imread(path)\n",
    "#     except:\n",
    "#         print(\"BROKEN: \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load in Psfs and initialize network to train\n",
    "\n",
    "Here we initialize with 9 PSFs taken from different parts in the field of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/ipykernel_2179836/3845168668.py\u001b[0m(30)\u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     28 \u001b[0;31m\u001b[0;31m# handle multiple sets of PSFs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m    \u001b[0;31m# FIXME: magic number 63 is 3*the number of PSFs per metafile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 30 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mmultiple_psfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m        \u001b[0mpsfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsfs_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(800, 1280, 21)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "import csv_psfs\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# load the PSFs\n",
    "if psf_loadtype == \"matlab\":\n",
    "    registered_psfs_path = filter_init_path\n",
    "    psfs = scipy.io.loadmat(registered_psfs_path)\n",
    "    psfs=psfs[filter_key]\n",
    "elif psf_loadtype == \"csv\":\n",
    "#     # expect a directory with a bunch of PSFs therein as separate csvs;\n",
    "#     # list out all csv file names in the directory\n",
    "#     psf_paths = glob.glob(psfs_path.removesuffix('/') + '/*')\n",
    "#     # iterate through that list,\n",
    "#     # open and append each to the psfs array,\n",
    "#     psfs = [[]]\n",
    "#     for path in psf_paths:\n",
    "#         #psfs[0].append(np.loadtxt(path, delimiter=',', encoding='utf-8-sig'))\n",
    "#         psfs[0].append(np.loadtxt(path, delimiter=','))\n",
    "#     # convert the psfs array to an np.ndarray\n",
    "#     psfs = np.transpose(np.asarray(psfs), (2,3,1,0))\n",
    "    set_trace()\n",
    "##     psfs = load_PSFs.load_PSFs_csv(psfs_path, meta_path, img_dims)[:,:,:,0]\n",
    "#     if not multiple_psfs: \n",
    "#         psfs = csv_psfs.pad_as_center(csv_psfs.load_from_dir(psfs_path), img_dims[1], img_dims[0])\n",
    "\n",
    "# handle multiple sets of PSFs:\n",
    "    # FIXME: magic number 63 is 3*the number of PSFs per metafile\n",
    "    if multiple_psfs:\n",
    "        psfs = np.empty((img_dims[1], img_dims[0], 21*3))\n",
    "        for i in range(len(psfs_paths)):\n",
    "            psfs[:,:,i:i+21] = csv_psfs.pad_as_center(csv_psfs.load_from_dir(psfs_paths[i]), img_dims[1], img_dims[0])\n",
    "    else:\n",
    "        psfs = csv_psfs.pad_as_center(csv_psfs.load_from_dir(psfs_path), img_dims[1], img_dims[0])\n",
    "else:\n",
    "    raise ValueError(\"Not sure how to load PSFs\")\n",
    "psfs.shape\n",
    "\n",
    "# for testing, cut the psf and look at padding behaviour\n",
    "#psfs = psfs[162:324, 216:432, :, :]\n",
    "#psfs.shape\n",
    "# Test result: it works!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1280, 21)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the PSFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc25a080820>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 10\n",
    "plt.imshow(psfs[368:432,608:672,ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it seems that the PSFs indeed start out centered. This means that something happens during training to cause them to shift around. I wonder if it's possible that the model I've been interrogating was trained on distorted data (that would explain this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(psfs_paths) == list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"string\") == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1280, 21)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_2179836/3554517495.py\u001b[0m(1)\u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'unet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    model =mod.UNet(486, 648, \n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m                             \u001b[0mencoding_cs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "(800, 1280, 21)\n",
      "(800, 1280, 21)\n"
     ]
    }
   ],
   "source": [
    "set_trace()\n",
    "\n",
    "if model_type=='unet':\n",
    "    model =mod.UNet(486, 648, \n",
    "                             encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                             center_cs=1024,\n",
    "                             decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                             skip_connections=[True, True, True, True, True, False])\n",
    "elif model_type=='wiener':\n",
    "\n",
    "    registered_psfs_path = filter_init_path\n",
    "    psfs = scipy.io.loadmat(registered_psfs_path)\n",
    "    psfs=psfs[filter_key]\n",
    "    psfs=psfs[:,:,0,0]\n",
    "    psfs=psfs/np.max(psfs)\n",
    "    \n",
    "    Ks=1\n",
    "\n",
    "    model = mod.UNet_wiener(486, 648, psfs, Ks, \n",
    "                             encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                             center_cs=1024,\n",
    "                             decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                             skip_connections=[True, True, True, True, True, False])\n",
    "    \n",
    "    print(psfs.shape, 1)\n",
    "    \n",
    "elif model_type=='multiwiener':\n",
    "    # assume psfs is already 3-dimensional if our PSFs are used\n",
    "    # if matlab-style is used, it's typically an academic who likes 4D\n",
    "    if psf_loadtype == \"matlab\":\n",
    "        psfs=psfs[:,:,:,0]\n",
    "    print(psfs.shape)\n",
    "    #psfs = cv2.resize(psfs, img_dims)\n",
    "    # rather than resizing, zero-pad to appropriate size\n",
    "    # this means that original PSF can be any size, but Image Delta must be set correctly\n",
    "    \n",
    "    print(psfs.shape)\n",
    "    psfs=psfs/np.max(psfs)\n",
    "    if multiple_psfs:\n",
    "        psfs_keep = psfs[:,:,list(range(0,11))+list(range(21,32))+list(range(43,54))]*1\n",
    "#         psfs_keep = psfs*1\n",
    "    #     psfs_keep = psfs[:,:,list(range(0,11))+list(range(21,32))]*1\n",
    "    #     psfs_keep = psfs[:,:,0:21]*1\n",
    "        print(psfs_keep.shape)\n",
    "\n",
    "    #     Ks =np.ones((1,1,psfs.shape[2]))\n",
    "        Ks_keep = np.ones((1,1,psfs_keep.shape[2]))\n",
    "        print(Ks_keep.shape)\n",
    "\n",
    "        model =mod.UNet_multiwiener_resize(img_dims[1], img_dims[0], psfs_keep, Ks_keep, \n",
    "                             encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                             center_cs=1024,\n",
    "                             decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                             skip_connections=[True, True, True, True, True, False], psfs_trainable=True)\n",
    "#     model =mod.UNet_multiwiener_resize(img_dims[1], img_dims[0], psfs, Ks, \n",
    "#                          encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "#                          center_cs=1024,\n",
    "#                          decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "#                          skip_connections=[True, True, True, True, True, False])\n",
    "\n",
    "# made PSFs untrainable\n",
    "    else:\n",
    "        Ks =np.ones((1,1,psfs.shape[2]))\n",
    "        model =mod.UNet_multiwiener_resize(img_dims[1], img_dims[0], psfs, Ks, \n",
    "                             encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "                             center_cs=1024,\n",
    "                             decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "                             skip_connections=[True, True, True, True, True, False], psfs_trainable=True,\n",
    "                                training_noise=True,\n",
    "                                training_noise_sigma=training_noise_sigma,\n",
    "                                pooling=pooling)\n",
    "#     model =mod.UNet_multiwiener_resize(img_dims[1], img_dims[0], psfs_keep, Ks_keep, \n",
    "#                          encoding_cs=[24, 64, 128, 256, 512, 1024],\n",
    "#                          center_cs=1024,\n",
    "#                          decoding_cs=[512, 256, 128, 64, 24, 24],\n",
    "#                          skip_connections=[True, True, True, True, True, False], psfs_trainable=True)\n",
    "    \n",
    "#     print('initialized filter shape:', psfs.shape, 'initialized K shape:', Ks.shape)\n",
    "# print('initialized filter shape:', psfs_keep.shape, 'initialized K shape:', Ks_keep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1280, 21)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 800, 1280,   0           []                               \n",
      "                                1)]                                                               \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNoise)  (None, 800, 1280, 1  0          ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " multi_wiener_deconvolution (Mu  (None, 800, 1280, 2  21504021   ['gaussian_noise[0][0]']         \n",
      " ltiWienerDeconvolution)        1)                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 800, 1280, 2  4536        ['multi_wiener_deconvolution[0][0\n",
      "                                4)                               ]']                              \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 800, 1280, 2  96         ['conv2d[0][0]']                 \n",
      " alization)                     4)                                                                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 800, 1280, 2  0           ['batch_normalization[0][0]']    \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 800, 1280, 2  5184        ['activation[0][0]']             \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 800, 1280, 2  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   4)                                                                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 800, 1280, 2  0           ['batch_normalization_1[0][0]']  \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 400, 640, 24  0          ['activation_1[0][0]']           \n",
      " ing2D)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 400, 640, 64  13824       ['average_pooling2d[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 400, 640, 64  256        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 400, 640, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 400, 640, 64  36864       ['activation_2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 400, 640, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 400, 640, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 200, 320, 64  0          ['activation_3[0][0]']           \n",
      " oling2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 200, 320, 12  73728       ['average_pooling2d_1[0][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 200, 320, 12  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 200, 320, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 200, 320, 12  147456      ['activation_4[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 200, 320, 12  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 200, 320, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 100, 160, 12  0          ['activation_5[0][0]']           \n",
      " oling2D)                       8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 100, 160, 25  294912      ['average_pooling2d_2[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 100, 160, 25  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 100, 160, 25  0           ['batch_normalization_6[0][0]']  \n",
      "                                6)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 100, 160, 25  589824      ['activation_6[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 100, 160, 25  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 100, 160, 25  0           ['batch_normalization_7[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 50, 80, 256)  0          ['activation_7[0][0]']           \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 50, 80, 512)  1179648     ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 50, 80, 512)  2048       ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 50, 80, 512)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 50, 80, 512)  2359296     ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 50, 80, 512)  2048       ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 50, 80, 512)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 25, 40, 512)  0          ['activation_9[0][0]']           \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 40, 1024  4718592     ['average_pooling2d_4[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 25, 40, 1024  4096       ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 25, 40, 1024  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 40, 1024  9437184     ['activation_10[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 25, 40, 1024  4096       ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 25, 40, 1024  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 12, 20, 1024  0          ['activation_11[0][0]']          \n",
      " oling2D)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 12, 20, 1024  9437184     ['average_pooling2d_5[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 12, 20, 1024  4096       ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 12, 20, 1024  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.image.resize (TFOpLambda)   (None, 25, 40, 1024  0           ['activation_12[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 25, 40, 2048  0           ['tf.image.resize[0][0]',        \n",
      "                                )                                 'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 25, 40, 512)  9437184     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 25, 40, 512)  2048       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 25, 40, 512)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 25, 40, 512)  2359296     ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 25, 40, 512)  2048       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 25, 40, 512)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 25, 40, 512)  2359296     ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 25, 40, 512)  2048       ['conv2d_15[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 25, 40, 512)  0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " tf.image.resize_1 (TFOpLambda)  (None, 50, 80, 512)  0          ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 50, 80, 1024  0           ['tf.image.resize_1[0][0]',      \n",
      "                                )                                 'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 50, 80, 256)  2359296     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 50, 80, 256)  1024       ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 50, 80, 256)  0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 50, 80, 256)  589824      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 50, 80, 256)  1024       ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 50, 80, 256)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 50, 80, 256)  589824      ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 50, 80, 256)  1024       ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 50, 80, 256)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " tf.image.resize_2 (TFOpLambda)  (None, 100, 160, 25  0          ['activation_18[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 100, 160, 51  0           ['tf.image.resize_2[0][0]',      \n",
      "                                2)                                'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 100, 160, 12  589824      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 100, 160, 12  512        ['conv2d_19[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 100, 160, 12  0           ['batch_normalization_19[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 100, 160, 12  147456      ['activation_19[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 100, 160, 12  512        ['conv2d_20[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 100, 160, 12  0           ['batch_normalization_20[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 100, 160, 12  147456      ['activation_20[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 100, 160, 12  512        ['conv2d_21[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 100, 160, 12  0           ['batch_normalization_21[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " tf.image.resize_3 (TFOpLambda)  (None, 200, 320, 12  0          ['activation_21[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 200, 320, 25  0           ['tf.image.resize_3[0][0]',      \n",
      "                                6)                                'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 200, 320, 64  147456      ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 200, 320, 64  256        ['conv2d_22[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 200, 320, 64  0           ['batch_normalization_22[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 200, 320, 64  36864       ['activation_22[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 200, 320, 64  256        ['conv2d_23[0][0]']              \n",
      " ormalization)                  )                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 200, 320, 64  0           ['batch_normalization_23[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 200, 320, 64  36864       ['activation_23[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 200, 320, 64  256        ['conv2d_24[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 200, 320, 64  0           ['batch_normalization_24[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.image.resize_4 (TFOpLambda)  (None, 400, 640, 64  0          ['activation_24[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 400, 640, 12  0           ['tf.image.resize_4[0][0]',      \n",
      "                                8)                                'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 400, 640, 24  27648       ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 400, 640, 24  96         ['conv2d_25[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 400, 640, 24  0           ['batch_normalization_25[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 400, 640, 24  5184        ['activation_25[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 400, 640, 24  96         ['conv2d_26[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 400, 640, 24  0           ['batch_normalization_26[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 400, 640, 24  5184        ['activation_26[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 400, 640, 24  96         ['conv2d_27[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 400, 640, 24  0           ['batch_normalization_27[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 800, 1280, 2  0           ['activation_27[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 800, 1280, 2  5184        ['up_sampling2d[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 800, 1280, 2  96         ['conv2d_28[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 800, 1280, 2  0           ['batch_normalization_28[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 800, 1280, 2  5184        ['activation_28[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 800, 1280, 2  96         ['conv2d_29[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 800, 1280, 2  0           ['batch_normalization_29[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 800, 1280, 2  5184        ['activation_29[0][0]']          \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 800, 1280, 2  96         ['conv2d_30[0][0]']              \n",
      " ormalization)                  4)                                                                \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 800, 1280, 2  0           ['batch_normalization_30[0][0]'] \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 800, 1280, 1  25          ['activation_30[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 800, 1280)   0           ['conv2d_31[0][0]']              \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 68,688,742\n",
      "Trainable params: 68,672,614\n",
      "Non-trainable params: 16,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if legacy_training:\n",
    "    model.build((None, img_dims[1], img_dims[0], 1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.any(np.isnan(psfs_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_reshaped = tf.convert_to_tensor(np.load(\"../data/fov_indicator.npy\").reshape((1,800,1280,1)), dtype=tf.float32)\n",
    "# indicator_reshaped = tf.convert_to_tensor(np.load(\"../data/fov_indicator.npy\"), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.unbatch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/tmp/ipykernel_2179836/4051516729.py\u001b[0m(4)\u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      2 \u001b[0;31m\u001b[0;31m# Prepare EpochLogger and load weights, if necessary, into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'debug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 4 \u001b[0;31m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mepochlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochlog\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done all the crap\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "done all the crap\n",
      "(None, 800, 1280, 1)\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.3964\n",
      "Epoch 20: saving model to saved_models/multiwiener_nV3_probe_noisy5_new_way2/model_weights\n",
      "7/7 [==============================] - 14s 1s/step - loss: 0.3964 - val_loss: 0.8484\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4385\n",
      "Program interrupted. (Use 'cont' to resume).\n",
      "> \u001b[0;32m/home/dshteinbok/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m(527)\u001b[0;36mread_variable_op\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    525 \u001b[0;31m      _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "\u001b[0m\u001b[0;32m    526 \u001b[0;31m        _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n",
      "\u001b[0m\u001b[0;32m--> 527 \u001b[0;31m      \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    528 \u001b[0;31m    \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    529 \u001b[0;31m      \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "# ADDED BY DANIEL:\n",
    "# Prepare EpochLogger and load weights, if necessary, into the model\n",
    "%debug\n",
    "set_trace()\n",
    "import epochlog.epochlog as el\n",
    "print(\"done all the crap\")\n",
    "\n",
    "## Training with TF.Dataset\n",
    "initial_learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False) #1e-3 diverges\n",
    "\n",
    "# what's the expected input shape for the model?\n",
    "exp_shape = model.get_config()[\"layers\"][0][\"config\"][\"batch_input_shape\"]\n",
    "print(exp_shape)\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "validtate_loss_results=[]\n",
    "num_epochs = 100\n",
    "loss_func=ut.SSIMLoss_l1_indicator\n",
    "learning_rate_counter=0\n",
    "#for epoch in range(num_epochs):\n",
    "if legacy_training:\n",
    "    epochlogger = el.EpochLogger(model, epochlog_location, training_location)\n",
    "    epochlogger.load_weights()\n",
    "    starting_epoch = epochlogger.epochs_done()\n",
    "    print(\"Starting on epoch number: \" + str(starting_epoch))\n",
    "    for epoch in range(starting_epoch, num_epochs):\n",
    "        validation_loss_avg=tf.keras.metrics.Mean()\n",
    "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "        epoch_accuracy = tf.keras.metrics.MeanSquaredError()\n",
    "\n",
    "        # Training loop\n",
    "        iter_num=0\n",
    "        for x, y in train_ds:\n",
    "            # Optimize the model\n",
    "            #print(\"x shape: \" + str(x.shape))\n",
    "            #print(\"y shape: \" + str(y.shape))\n",
    "            # NOTICE: x.shape = y.shape = (2, 486, 648, 1)\n",
    "            # TODO: resize x and y based on expected dimensions for the model\n",
    "            # Crop to the top left corner of the image to make it fit our size if it is too large\n",
    "            if x.shape[1] > exp_shape[1]:\n",
    "                x = x[:,:exp_shape[1],:,:]\n",
    "            if x.shape[2] > exp_shape[2]:\n",
    "                x = x[:,:,:exp_shape[2],:]\n",
    "            if y.shape[1] > exp_shape[1]:\n",
    "                y = y[:,:exp_shape[1],:,:]\n",
    "            if y.shape[2] > exp_shape[2]:\n",
    "                y = y[:,:,:exp_shape[2],:]\n",
    "    #         loss_value, grads = ut.grad(model,loss_func, x, y)\n",
    "    #         loss_value, grads = ut.grad_universal(model,loss_func, x, y)\n",
    "            if crazy_external_noise_addition:\n",
    "                xy_shifted_arr = denoising.rescale_to_one(\n",
    "                    np.asarray([x + np.random.normal(scale=training_noise_sigma, size=x.shape),y]))\n",
    "                loss_value, grads = ut.grad_universal(model,loss_func, xy_shifted_arr[0], xy_shifted_arr[1].astype(np.float32), \n",
    "                                                      indicator_reshaped, training=False)\n",
    "            else:\n",
    "                loss_value, grads = ut.grad_universal(model,loss_func, x, y, indicator_reshaped)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            # Track progress\n",
    "            epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "\n",
    "            epoch_accuracy.update_state(y, model(x)) \n",
    "            # Print every 1\n",
    "            if iter_num % 1 == 0:\n",
    "                print(\"Epoch {:03d}: Step: {:03d}, Loss: {:.3f}, MSE: {:.3}\".format(epoch, iter_num,epoch_loss_avg.result(),\n",
    "                                                                            epoch_accuracy.result()),end='\\r')\n",
    "            iter_num=iter_num+1\n",
    "\n",
    "\n",
    "\n",
    "      # End epoch\n",
    "        #print(\"Ending Epoch\")\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "\n",
    "        # skip validation, since SSIM function is broken\n",
    "        for x_val, y_val in val_ds:\n",
    "            val_loss_value= loss_func(model, x_val, y_val, indicator_reshaped)\n",
    "            validation_loss_avg.update_state(val_loss_value)\n",
    "\n",
    "\n",
    "        validtate_loss_results.append(validation_loss_avg.result())    \n",
    "        #if epoch % 1 == 0:\n",
    "            #print(\"Epoch {:03d}: MSE: {:.3}, Training Loss: {:.3f}, Validation Loss: {:.3f}\".format(epoch,\n",
    "            #                                                            epoch_accuracy.result(), epoch_loss_avg.result(), \n",
    "            #                                                                                        validation_loss_avg.result()))\n",
    "        epochlogger.done_epoch()\n",
    "else:\n",
    "#     loss_func=ut.SSIMLoss_l1_indicator_generator(indicator_reshaped, training=False)\n",
    "#     loss_func=ut.SSIMLoss_l1_generator(training=False)\n",
    "    loss_func = ut.SSIMLoss_l1_indicator_Class(indicator_reshaped)\n",
    "#     loss_func=ut.Loss_l1_indicator_generator(indicator_reshaped, training=False)\n",
    "    # load the dataset here? Necessary to have separate x and y datasets because that's how fit() takes it\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=training_location,\n",
    "    save_weights_only=True,\n",
    "    verbose=1)\n",
    "    \n",
    "    if backup_location is None:\n",
    "        backup_restore_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=training_location)\n",
    "    else:\n",
    "        backup_restore_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=backup_location)\n",
    "#     model_checkpoint_callback\n",
    "    \n",
    "    model.compile(optimizer, loss=loss_func)\n",
    "#     print(model_checkpoint_callback.best)\n",
    "\n",
    "#     model.load_weights(training_location)\n",
    "    # weirdly, model keeps restarting its training from the first epoch\n",
    "    # made the modification below based on user30012's answer at\n",
    "    # https://stackoverflow.com/questions/45393429/keras-how-to-save-model-and-continue-training\n",
    "#     score = model.evaluate(val_ds)\n",
    "#     model_checkpoint_callback.best = score\n",
    "    \n",
    "#     epochlogger = el.BaseEpochLogger(model, epochlog_location, training_location)\n",
    "#     epochlogger.load_weights()\n",
    "    \n",
    "#     print(model_checkpoint_callback.best)\n",
    "    model.fit(train_ds, epochs=num_epochs, callbacks=[model_checkpoint_callback, backup_restore_callback], \n",
    "             validation_data=val_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if legacy_training:\n",
    "    import epochlog.epochlog as el\n",
    "    epochlogger = el.EpochLogger(model, epochlog_location, training_location)\n",
    "    epochlogger.load_weights()\n",
    "else:\n",
    "    model.load_weights(training_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('./saved_models/multiwiener')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "plt.imshow(imageio.imread(\"/home/dshteinbok/noisy_real_images/10.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch, target_batch = next(iter(val_ds))\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on validation data\n",
    "input_batch, target_batch = next(iter(val_ds))\n",
    "imnum=0\n",
    "\n",
    "# noisy_input = input_batch + np.random.normal(scale=training_noise_sigma, size=input_batch.shape)\n",
    "noisy_input = input_batch\n",
    "f, ax = plt.subplots(3, 1, figsize=(15,15))\n",
    "# ax[0].imshow((target_batch[imnum,:,:,0]))\n",
    "ax[0].imshow((target_batch[imnum,:,:]))\n",
    "ax[0].set_title('Target Data')\n",
    "\n",
    "# test=model(input_batch[imnum,:,:,0].numpy().reshape((1,486, 648,1)))\n",
    "test=model(noisy_input[imnum,:,:].numpy().reshape((1,img_dims[1], img_dims[0],1)))\n",
    "ax[2].set_title('recon')\n",
    "ax[2].imshow(test[0,:,:1200])\n",
    "\n",
    "ax[1].imshow((noisy_input[imnum,:,:]))\n",
    "ax[1].set_title('Input Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isnan(test[0,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_reconstruct_index = 9\n",
    "# folderpath = \"/home/dshteinbok/real_images/\"\n",
    "# to_reconstruct = imageio.imread(folderpath+\"image_\"+str(to_reconstruct_index)+\".png\")\n",
    "# img_path_to_do = \"/home/dshteinbok/denoised_real_images/30.png\"\n",
    "img_path_to_do = \"/home/dshteinbok/noisy_real_images/40.png\"\n",
    "to_reconstruct = cv2.resize(imageio.imread(img_path_to_do), (1280, 800))\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(15,15))\n",
    "axs[0].imshow(to_reconstruct)\n",
    "axs[1].imshow(model(to_reconstruct.reshape((1,800,1280,1)))[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(80,128))\n",
    "plt.imshow(model(to_reconstruct.reshape((1,800,1280,1)))[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imageio.imread(\"/home/dshteinbok/real_images_unpadded/isxd_9.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training is working, save your model using: \n",
    "\n",
    "    model.save_weights('./saved_models/model_name')\n",
    "\n",
    "You can save after training is complete, or periodically throughout epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first PSF as an example of what we're looking for\n",
    "plt.imshow(psfs[:,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

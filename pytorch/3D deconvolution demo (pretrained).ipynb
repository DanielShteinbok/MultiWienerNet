{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os, sys, glob, cv2, hdf5storage, time\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms\n",
    "import scipy.io\n",
    "\n",
    "import models.dataset as ds\n",
    "import helper as hp\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rc('image', cmap='inferno')\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = 'cuda:0'\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiWienerNet 3D Deconvolution Demo\n",
    "\n",
    "In this Jupyter Notebook, we take a pretrained MultiWienerNet and demonstrate fast spatially-varying deconvolutions using both simulated and real data. We compare the performance against a pre-trained U-Net, WienerNet (non-spatially-varying), and spatially-varying FISTA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths to saved models\n",
    "multiwiener_file_path='saved_models/trained_multiwiener3D/'\n",
    "unet_file_path='saved_models/trained_unet3D/'\n",
    "wiener_file_path='saved_models/trained_wiener3D/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = hp.load_pretrained_model(unet_file_path,model_type = 'unet', device = device)\n",
    "wiener_model = hp.load_pretrained_model(wiener_file_path, model_type = 'wiener', device = device)\n",
    "multiwiener_model = hp.load_pretrained_model(multiwiener_file_path, model_type = 'multiwiener', device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEAN UP\n",
    "down_size = ds.downsize(ds=.75)\n",
    "to_tensor = ds.ToTensor()\n",
    "add_noise=ds.AddNoise()\n",
    "\n",
    "filepath_gt = '../data/3D_data_simulated/'\n",
    "\n",
    "filepath_all=glob.glob(filepath_gt+'*')\n",
    "filepath_test=filepath_all\n",
    "\n",
    "dataset_test = ds.MiniscopeDataset(filepath_test, transform = transforms.Compose([down_size,add_noise,to_tensor]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run deconvolution for simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ind = 1   # We provide 2 sample images: 0 and 1 \n",
    "sample_batched = dataset_test.__getitem__(img_ind)\n",
    "meas_np = hp.to_np(sample_batched['meas'])\n",
    "sample_batched['meas'] = sample_batched['meas'].unsqueeze(0)\n",
    "\n",
    "plt.imshow(meas_np);\n",
    "plt.title('measurement');\n",
    "print('measurement shape:', meas_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deconvolve! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list = []\n",
    "with torch.no_grad():\n",
    "    t0 = time.time()\n",
    "    out_unet = unet_model(sample_batched['meas'].repeat(1,1,32,1,1).to(device))\n",
    "    t_list.append(time.time() - t0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    out_wiener = wiener_model((sample_batched['meas']).to(device))\n",
    "    t_list.append(time.time() - t0)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    out_multiwiener = multiwiener_model((sample_batched['meas']).to(device))\n",
    "    t_list.append(time.time() - t0)\n",
    "    \n",
    "recon_titles = ['Unet', 'WienerNet', 'MultiWienerNet (Ours)']\n",
    "recon_list = [out_unet, out_wiener, out_multiwiener]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_np = hp.to_np(sample_batched['im_gt'].unsqueeze(0))\n",
    "recons_np = []\n",
    "for i in range(0,len(recon_list)):\n",
    "    recons_np.append(hp.to_np(recon_list[i]))\n",
    "\n",
    "f, ax = plt.subplots(1, 4, figsize=(15,15))\n",
    "ax[0].imshow(hp.max_proj(gt_np))\n",
    "ax[0].set_title('Ground Truth')\n",
    "for i in range(0,len(recons_np)):\n",
    "    ax[i+1].imshow(hp.max_proj(recons_np[i]))\n",
    "    ax[i+1].set_title(recon_titles[i])\n",
    "    \n",
    "for i in range(0,len(recons_np)):\n",
    "    print(recon_titles[i], ': ', np.round(t_list[i],2),'s,  PSNR: ', np.round(hp.calc_psnr(gt_np, recons_np[i]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_np = recons_np[-1]\n",
    "def plot_slider(x):\n",
    "    f, ax = plt.subplots(1, 4, figsize=(15,15))\n",
    "    plt.title('Reconstruction: frame %d'%(x))\n",
    "   \n",
    "    ax[0].imshow(gt_np[x],vmin=0, vmax=np.max(gt_np))\n",
    "    ax[0].set_title('Ground Truth, frame %d'%(x))\n",
    "    ax[0].axis('off')\n",
    "    for i in range(0,len(recons_np)):\n",
    "        ax[i+1].imshow(recons_np[i][x], vmin=0, vmax=np.max(recons_np[i]))\n",
    "        ax[i+1].set_title(recon_titles[i])\n",
    "        ax[i+1].axis('off')\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "interactive(plot_slider,x=(0,out_np.shape[0]-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare against spatially-varying FISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare to fista\n",
    "saved_fista = [ 'fista3D-fourCells.mat', 'fista3D-cellcool.mat',]\n",
    "\n",
    "Ifista=scipy.io.loadmat('../data/' + saved_fista[img_ind])\n",
    "Ifista=Ifista['xhat_out']\n",
    "Ifista=Ifista.transpose([2,0,1])/np.max(Ifista)\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "ax[0].imshow(hp.max_proj(Ifista))\n",
    "ax[0].set_title('FISTA result')\n",
    "ax[1].imshow(hp.max_proj(recons_np[-1]))\n",
    "ax[1].set_title(recon_titles[-1])\n",
    "\n",
    "print('FISTA PSNR: ', np.round(hp.calc_psnr(gt_np, Ifista),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run deconvolution for real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ind = 0 # 0: resolution target, 1: waterbear\n",
    "\n",
    "loaded_meas = glob.glob('../data/real_data/*')\n",
    "meas_loaded = scipy.io.loadmat(loaded_meas[img_ind])['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas=meas_loaded[18:466,4:644]\n",
    "meas= cv2.resize(meas, (0,0), fx=0.75, fy=0.75) \n",
    "meas_tensor=torch.tensor(meas, dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0).unsqueeze(0)\n",
    "plt.imshow(meas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    meas_t = meas_tensor.repeat(1,1,32,1,1)\n",
    "    out_unet = unet_model(meas_t.to(device))\n",
    "    out_wiener = wiener_model((meas_t).to(device))\n",
    "    out_multiwiener = multiwiener_model((meas_t).to(device))\n",
    "    \n",
    "    recon_titles = ['Unet', 'WienerNet', 'MultiWienerNet (Ours)']\n",
    "    recon_list = [out_unet, out_wiener, out_multiwiener]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    out_wiener = wiener_model.wiener_model(meas_t.to(device))\n",
    "\n",
    "    out_multiwiener = multiwiener_model.wiener_model(meas_t.to(device))\n",
    "\n",
    "    \n",
    "plt.imshow(out_multiwiener[0,4,0].detach().cpu().numpy()); plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_np = []\n",
    "for i in range(0,len(recon_list)):\n",
    "    recons_np.append(hp.to_np(recon_list[i]))\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(15,15))\n",
    "for i in range(0,len(recons_np)):\n",
    "    if img_ind == 0:\n",
    "        ax[i].imshow(recons_np[i][1])\n",
    "    else:\n",
    "        ax[i].imshow(hp.max_proj(recons_np[i]))\n",
    "    ax[i].set_title(recon_titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slider(x):\n",
    "    f, ax = plt.subplots(1, 3, figsize=(15,15))\n",
    "    plt.title('Reconstruction: frame %d'%(x))\n",
    "   \n",
    "    for i in range(0,len(recons_np)):\n",
    "        ax[i].imshow(recons_np[i][x], vmin=0, vmax=np.max(recons_np[i]))\n",
    "        ax[i].axis('off')\n",
    "        \n",
    "        if i ==0:\n",
    "            ax[i].set_title('Unet, frame %d'%(x))\n",
    "        else:\n",
    "            ax[i].set_title(recon_titles[i])\n",
    "        \n",
    "    return x\n",
    "\n",
    "\n",
    "interactive(plot_slider,x=(0,out_np.shape[0]-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run deconvolution movie for real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterbear=hdf5storage.loadmat('/media/lahvahndata/Kyrollos/LearnedMiniscope3D/real_data/waterbear_all.mat') \n",
    "waterbear=waterbear['b']\n",
    "waterbear=(waterbear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterbear.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas=waterbear[18:466,4:644,:]\n",
    "meas= cv2.resize(meas, (0,0), fx=0.75, fy=0.75) \n",
    "meas_tensor=torch.tensor(meas, dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0).unsqueeze(0)\n",
    "plt.imshow(meas[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slider(x):\n",
    "    plt.title('Reconstruction: frame %d'%(x))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(meas[...,x])\n",
    "    return x\n",
    "\n",
    "\n",
    "interactive(plot_slider,x=(0,meas.shape[-1]-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_bear_xy=[]\n",
    "out_bear_yz=[]\n",
    "for t in range(30):\n",
    "    \n",
    "    print('processing image: ', t, end='\\r')\n",
    "    with torch.no_grad():\n",
    "        out_waterbear=multiwiener_model(meas_tensor[...,t])  #.repeat(1,1,32,1,1)\n",
    "    out_waterbear_np = out_waterbear.detach().cpu().numpy()[0,0]\n",
    "    \n",
    "    out_bear_xy.append(np.max(out_waterbear_np,0))\n",
    "    out_bear_yz.append(np.max(out_waterbear_np,2))\n",
    "    \n",
    "    \n",
    "#     plt.imshow(out_bear_xy[-1])\n",
    "#     plt.title(t)\n",
    "#     plt.show()\n",
    "#     clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_bear_xy=np.array(out_bear_xy)\n",
    "out_bear_yz=np.array(out_bear_yz)\n",
    "# test=test.transpose([1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slider(x):\n",
    "    f, ax = plt.subplots(1, 3, figsize=(15,3))\n",
    "    \n",
    "   \n",
    "    ax[0].imshow(meas[...,x], vmin=0, vmax=np.max(meas))\n",
    "    ax[1].imshow(out_bear_xy[x], vmin=0, vmax=np.max(out_bear_xy))\n",
    "    ax[2].imshow(out_bear_yz[x].transpose(), vmin=0, vmax=np.max(out_bear_yz))\n",
    "    \n",
    "    ax[0].set_title('Measurement')\n",
    "    ax[1].set_title('Reconstruction: frame %d'%(x))\n",
    "    \n",
    "    ax[0].axis('off')\n",
    "    ax[1].axis('off')\n",
    "    ax[2].axis('off')\n",
    "        \n",
    "       \n",
    "    return x\n",
    "\n",
    "\n",
    "interactive(plot_slider,x=(0,out_bear_xy.shape[0]-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned PSFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_psfs_wiener_np=wiener_model.wiener_model.psfs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slider(x):\n",
    "    plt.title('Reconstruction: frame %d'%(x))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(learned_psfs_wiener_np[x])\n",
    "    return x\n",
    "\n",
    "\n",
    "interactive(plot_slider,x=(0,learned_psfs_wiener_np.shape[0]-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_psfs_np=multiwiener_model.wiener_model.psfs.detach().cpu().numpy()\n",
    "learned_Ks_np=multiwiener_model.wiener_model.Ks.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slider(x):\n",
    "    plt.title('Reconstruction: frame %d'%(x))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(learned_psfs_np[4][x])\n",
    "    return x\n",
    "\n",
    "\n",
    "interactive(plot_slider,x=(0,learned_psfs_np.shape[1]-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=20\n",
    "plt.imshow(np.abs(learned_psfs_np[8][x]-learned_psfs_np[0][x])); plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiwiener_torch3",
   "language": "python",
   "name": "multiwiener_torch3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

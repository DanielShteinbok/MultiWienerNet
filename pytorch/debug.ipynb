{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torch.optim\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "import os, sys, json, glob\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import skimage.io\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import cv2\n",
    "import models.wiener_model as wm\n",
    "import models.dataset as ds\n",
    "from PIL import Image\n",
    "import helper as hp\n",
    "\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Process some integers.')\n",
    "parser.add_argument('--data_type', default='2D')\n",
    "parser.add_argument('--network', default='multiwiener') #'wiener' or 'unet' or 'multiwiener'\n",
    "parser.add_argument('--id', default='new_unet2') #some identifier\n",
    "parser.add_argument('--loss_type', default='l1') \n",
    "parser.add_argument('--device', default='0') \n",
    "parser.add_argument('--psf_num', default=9, type=int)\n",
    "parser.add_argument('--psf_ds', default=0.75, type=float)\n",
    "parser.add_argument('--epochs', default=10000, type=int)\n",
    "parser.add_argument('--lr', default=1e-4, type=float) \n",
    "parser.add_argument('--batch_size', default=4, type=int) \n",
    "parser.add_argument('--load_path',default=None)\n",
    "parser.add_argument('--save_checkponts',default=True)\n",
    "\n",
    "#args = parser.parse_args()\n",
    "args = parser.parse_args(''.split())\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing 9 psfs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# for 3D-UNet multiwiener\n",
    "registered_psfs_path = '../data/multiWienerPSFStack_40z_aligned.mat'\n",
    "psfs = scipy.io.loadmat(registered_psfs_path)\n",
    "psfs=psfs['multiWienerPSFStack_40z']\n",
    "\n",
    "if args.data_type == '3D':\n",
    "    if args.network=='wiener' or args.network=='unet':\n",
    "        psfs=hp.pre_process_psfs(psfs)[:,:,4]\n",
    "        Ks=np.ones((32,1,1))\n",
    "        print('choosing 1 psfs')\n",
    "\n",
    "    elif args.network=='multiwiener':\n",
    "        Ks=np.ones((args.psf_num,32,1,1))\n",
    "        if args.psf_num==9:\n",
    "            print('choosing 9 psfs')\n",
    "            psfs=hp.pre_process_psfs(psfs)\n",
    "    else:\n",
    "        print('invalid network')\n",
    "    psfs = hp.downsize_psf(psfs)\n",
    "else: #2D\n",
    "    if args.network=='wiener' or args.network=='unet':\n",
    "        psfs=hp.pre_process_psfs_2d(psfs)[:,:,4, 0]\n",
    "        Ks= 1.\n",
    "        print('choosing 1 psfs')\n",
    "\n",
    "    elif args.network=='multiwiener':\n",
    "        Ks=np.ones((args.psf_num,1,1))\n",
    "        if args.psf_num==9:\n",
    "            print('choosing 9 psfs')\n",
    "            psfs=hp.pre_process_psfs_2d(psfs)[...,0]\n",
    "            psfs = psfs.transpose(2,0,1)\n",
    "    else:\n",
    "        print('invalid network')\n",
    "\n",
    "    \n",
    "down_size = ds.downsize(ds=args.psf_ds)\n",
    "to_tensor = ds.ToTensor()\n",
    "add_noise=ds.AddNoise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of images 22126\n",
      "training images: 17700 testing images: 4426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if args.data_type == '3D':\n",
    "    filepath_gt = '/home/kyrollos/LearnedMiniscope3D/Data3D/Training_data_all/' \n",
    "else:\n",
    "    filepath_gt = '/home/kyrollos/LearnedMiniscope3D/Data/Target/'\n",
    "    filepath_meas = '/home/kyrollos/LearnedMiniscope3D/Data/Train/'\n",
    "\n",
    "\n",
    "filepath_all=glob.glob(filepath_gt+'*')\n",
    "random.Random(8).shuffle(filepath_all)\n",
    "print('total number of images',len(filepath_all))\n",
    "total_num_images = len(filepath_all)\n",
    "num_test = 0.2 # 20% test\n",
    "filepath_train=filepath_all[0:int(total_num_images*(1-num_test))]\n",
    "filepath_test=filepath_all[int(total_num_images*(1-num_test)):]\n",
    "\n",
    "print('training images:', len(filepath_train), \n",
    "      'testing images:', len(filepath_test))\n",
    "\n",
    "if args.data_type == '3D':\n",
    "    dataset_train = ds.MiniscopeDataset(filepath_train, transform = transforms.Compose([down_size,add_noise,to_tensor]))\n",
    "    dataset_test = ds.MiniscopeDataset(filepath_test, transform = transforms.Compose([down_size,add_noise,to_tensor]))\n",
    "else:\n",
    "    dataset_train = ds.MiniscopeDataset_2D(filepath_train, filepath_meas, transform = transforms.Compose([ds.crop2d(),ds.ToTensor2d()]))\n",
    "    dataset_test = ds.MiniscopeDataset_2D(filepath_test, filepath_meas, transform = transforms.Compose([ds.crop2d(),ds.ToTensor2d()]))\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=args.batch_size,\n",
    "                        shuffle=True, num_workers=1)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=args.batch_size,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "if args.data_type == '3D':\n",
    "    from models.unet3d import Unet\n",
    "    unet_model = Unet(n_channel_in=args.psf_num, n_channel_out=1, residual=False, down='conv', up='tconv', activation='selu').to(device)\n",
    "\n",
    "    if args.network == 'multiwiener' or args.network == 'wiener':\n",
    "        wiener_model=wm.WienerDeconvolution3D(psfs,Ks).to(device)\n",
    "        model=wm.MyEnsemble(wiener_model,unet_model)\n",
    "    else:\n",
    "        model = unet_model\n",
    "else: #2D\n",
    "    from models.unet2 import UNet\n",
    "    if args.network == 'multiwiener':\n",
    "        num_in_channels = args.psf_num\n",
    "    else:\n",
    "        num_in_channels = 1\n",
    "        \n",
    "    #unet_model = Unet(n_channel_in=num_in_channels, n_channel_out=1, residual=False, down='conv', up='tconv', activation='selu').to(device)\n",
    "    unet_model = UNet(n_channels=num_in_channels, n_classes=1).to(device)\n",
    "\n",
    "    if args.network == 'multiwiener' or args.network == 'wiener':\n",
    "        wiener_model=wm.WienerDeconvolution3D(psfs,Ks).to(device)\n",
    "        model=wm.MyEnsemble(wiener_model,unet_model)\n",
    "    else:\n",
    "        model = unet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.load_path is not None:\n",
    "    model.load_state_dict(torch.load('saved_data/'+args.load_path,map_location=torch.device(device)))\n",
    "    print('loading saved model')\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "ssim_loss = SSIM(win_size=11, win_sigma=1.5, data_range=1, size_average=True, channel=1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "\n",
    "if args.save_checkponts == True:\n",
    "    filepath_save = 'saved_data/' +\"_\".join((list(vars(args).values()))[0:5]) + \"/\"\n",
    "\n",
    "    if not os.path.exists(filepath_save):\n",
    "        os.makedirs(filepath_save)\n",
    "\n",
    "    with open(filepath_save + 'args.json', 'w') as fp:\n",
    "        json.dump(vars(args), fp)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyrollos/anaconda3/envs/torch_anaconda/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448233824/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for testing set  0   1106 78.378226496279242976\n",
      "loss for testing set  1   1106 71.941382549703122068\n",
      "loss for testing set  2   1106 74.401428252458570695\n",
      "loss for testing set  3   1106 71.045484699308877864\n",
      "epoch:  4  batch:  1800  loss:  0.108448676764965064\r"
     ]
    }
   ],
   "source": [
    "best_loss=27e7\n",
    "\n",
    "for itr in range(0,args.epochs):\n",
    "    for i_batch, sample_batched in enumerate(dataloader_train):\n",
    "        optimizer.zero_grad()\n",
    "        #sample_batched['meas'] = sample_batched['meas']*255.\n",
    "        #out = model(sample_batched['meas'].repeat(1,32,1,1)[...,18:466,4:644].unsqueeze(0).to(device))\n",
    "        if args.network=='unet' and args.data_type == '3D':\n",
    "            out = model(sample_batched['meas'].repeat(1,1,32,1,1).to(device))\n",
    "        else:\n",
    "            out = model(sample_batched['meas'].to(device))\n",
    "\n",
    "        if args.loss_type=='l1':\n",
    "            loss = loss_fn(out, sample_batched['im_gt'].to(device))\n",
    "        else:\n",
    "            #loss = loss_fn(out, sample_batched['im_gt'].to(device))+ (1- ms_ssim( out[0], sample_batched['im_gt'][0].to(device), data_range=1, size_average=False))\n",
    "            \n",
    "            loss = loss_fn(out, sample_batched['im_gt'].to(device)) + (1-ssim_loss(out, sample_batched['im_gt'].to(device)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.wiener_model.Ks.data = model.wiener_model.Ks.data.clamp(0,1e9)\n",
    "        \n",
    "        if i_batch %100 ==0:\n",
    "            print('epoch: ', itr, ' batch: ', i_batch, ' loss: ', loss.item(), end='\\r')\n",
    "\n",
    "        #break \n",
    "    if args.data_type == '3D':\n",
    "        out_np = np.max(out.detach().cpu().numpy()[0,0],0)\n",
    "        gt_np = np.max(sample_batched['im_gt'].detach().cpu().numpy()[0,0],0)\n",
    "        meas_np = np.max(sample_batched['meas'].detach().cpu().numpy()[0,0],0)\n",
    "    else:\n",
    "        out_np = out.detach().cpu().numpy()[0][0]\n",
    "        gt_np = sample_batched['im_gt'].detach().cpu().numpy()[0][0]\n",
    "        meas_np = sample_batched['meas'].detach().cpu().numpy()[0][0]\n",
    "\n",
    "\n",
    "    if args.save_checkponts == True:\n",
    "        torch.save(model.state_dict(), filepath_save + 'model_noval.pt')\n",
    "    \n",
    "    if itr%1==0:\n",
    "        total_loss=0\n",
    "        for i_batch, sample_batched in enumerate(dataloader_test):\n",
    "            sample_batched['meas'] = sample_batched['meas']*255.\n",
    "            with torch.no_grad():\n",
    "                if args.network=='unet' and args.data_type == '3D':\n",
    "                    out = model(sample_batched['meas'].repeat(1,1,32,1,1).to(device))\n",
    "                else:\n",
    "                    out = model(sample_batched['meas'].to(device))\n",
    "                if args.loss_type=='l1':\n",
    "                    loss = loss_fn(out, sample_batched['im_gt'].to(device))\n",
    "                else:\n",
    "                    loss = loss_fn(out, sample_batched['im_gt'].to(device)) + (1-ssim_loss(out, sample_batched['im_gt'].to(device)))\n",
    "        \n",
    "                    #loss = loss_fn(out, sample_batched['im_gt'].to(device))+(1- ms_ssim( out, sample_batched['im_gt'][0].to(device), data_range=1, size_average=False))\n",
    "                \n",
    "                \n",
    "                total_loss+=loss.item()\n",
    "                \n",
    "        print('loss for testing set ',itr,' ',i_batch, total_loss)\n",
    "                \n",
    "            #break\n",
    "        \n",
    "        if args.save_checkponts == True:\n",
    "            im_gt = Image.fromarray((np.clip(gt_np/np.max(gt_np),0,1)*255).astype(np.uint8))\n",
    "            im = Image.fromarray((np.clip(out_np/np.max(out_np),0,1)*255).astype(np.uint8))\n",
    "            im.save(filepath_save + str(itr) + '.png')\n",
    "            im_gt.save(filepath_save + 'gt.png')\n",
    "        \n",
    "        \n",
    "        if total_loss<best_loss:\n",
    "            best_loss=total_loss\n",
    "\n",
    "            # save checkpoint\n",
    "            if args.save_checkponts == True:\n",
    "                torch.save(model.state_dict(), filepath_save + 'model.pt')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-anaconda",
   "language": "python",
   "name": "torch-anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
